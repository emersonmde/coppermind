[package]
name = "coppermind"
version = "0.1.0"
authors = ["Matthew Emerson <emersonmde@protonmail.com>"]
edition = "2021"

[lib]
name = "coppermind"
path = "src/lib.rs"
crate-type = ["cdylib", "rlib"]

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
# Cross-platform dependencies
dioxus = { version = "0.7.1", features = [] }
futures = "0.3"
futures-channel = "0.3"
futures-util = "0.3"
candle-core = "0.8.0"
candle-nn = "0.8.0"
candle-transformers = "0.8.0"
serde = { version = "1.0", features = ["derive"] }
safetensors = "0.4"
tokenizers = { version = "0.20", default-features = false, features = ["unstable_wasm"] }
once_cell = "1.19"

# wasm-bindgen + web APIs: used in embedding/cpu/wgpu modules
# (safe to include on all platforms - browser APIs won't be called on desktop)
wasm-bindgen = "0.2"
wasm-bindgen-futures = "0.4"
console_error_panic_hook = "0.1"
js-sys = "0.3"
serde-wasm-bindgen = "0.6"
web-sys = { version = "0.3", features = [
    "Worker", "WorkerOptions", "WorkerType", "MessageEvent", "console", "Blob", "Url", "Window", "Navigator",
    "DedicatedWorkerGlobalScope", "Request", "RequestInit", "RequestMode", "Response", "Headers",
    "Document", "Element", "NodeList", "HtmlScriptElement"
] }

# Hybrid Search dependencies
async-trait = "0.1"
bm25 = "2.3"
instant-distance = "0.6"

# Text chunking (semantic splitting)
# Note: We implement our own ChunkSizer instead of using the tokenizers feature
# to avoid pulling in onig (C library) which breaks WASM builds
text-splitter = { version = "0.18", default-features = false }

# Error handling with derive macros
thiserror = "2.0"

# Text processing
regex = "1.11"

# Cross-platform timing (works on WASM and native)
instant = { version = "0.1", features = ["wasm-bindgen"] }

[target.'cfg(target_arch = "wasm32")'.dependencies]
# WASM-only dependencies
getrandom = { version = "0.3", features = ["wasm_js"] }
gloo-timers = { version = "0.3", features = ["futures"] }

# OPFS storage features (web-only)
web-sys = { version = "0.3", features = [
    "FileSystemDirectoryHandle",
    "FileSystemFileHandle",
    "FileSystemWritableFileStream",
    "FileSystemSyncAccessHandle",
    "FileSystemGetFileOptions",
    "FileSystemRemoveOptions",
    "StorageManager",
    "File"
] }

[target.'cfg(not(target_arch = "wasm32"))'.dependencies]
# Native filesystem for desktop
tokio = { version = "1", features = ["fs", "rt", "macros"] }

[target.'cfg(any(target_os = "macos", target_os = "ios"))'.dependencies]
# GPU acceleration features for Apple platforms (Metal + Accelerate)
# Supports macOS desktop and iOS/iPadOS mobile
candle-core = { version = "0.8.0", features = ["metal", "accelerate"] }
candle-nn = { version = "0.8.0", features = ["metal", "accelerate"] }
candle-transformers = { version = "0.8.0", features = ["metal", "accelerate"] }

[target.'cfg(all(not(target_arch = "wasm32"), not(any(target_os = "macos", target_os = "ios")), any(target_arch = "x86_64", target_arch = "x86")))'.dependencies]
# Intel MKL CPU optimization for x86/x86_64 platforms (Windows, Linux)
# Excluded from Apple platforms which use Accelerate instead
candle-core = { version = "0.8.0", features = ["mkl"] }
candle-nn = { version = "0.8.0", features = ["mkl"] }
candle-transformers = { version = "0.8.0", features = ["mkl"] }

[features]
default = ["web"]
web = ["dioxus/web"]
desktop = ["dioxus/desktop"]
mobile = ["dioxus/mobile"]
# Optional CUDA support for NVIDIA GPUs (requires CUDA toolkit installed)
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
# Enhanced CUDA with cuDNN for deep learning (requires CUDA + cuDNN installed)
# Note: cudnn feature only available in candle-core
cudnn = ["cuda", "candle-core/cudnn"]

[profile]

[profile.wasm-dev]
inherits = "dev"
opt-level = 1

[profile.server-dev]
inherits = "dev"

[profile.android-dev]
inherits = "dev"

# See `.cargo/config.toml` for WASM-specific rustflags and memory limits.
